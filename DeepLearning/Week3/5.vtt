WEBVTT

1
00:00:00.000 --> 00:00:01.530
Trong video trước đó,

2
00:00:01.530 --> 00:00:06.885
chúng ta đã thấy khi đặt các ví dụ huấn luyện 
cạnh nhau theo chiều ngang trong ma trận X,

3
00:00:06.885 --> 00:00:11.158
thì bạn có thể suy ra một triển khai vector
 hóa của bước truyền xuôi qua mạng nơ-ron nhân tạo.

4
00:00:11.158 --> 00:00:14.760
Chúng ta sẽ nói thêm một chút về lý do 
tại sao các phương trình chúng ta đã viết

5
00:00:14.760 --> 00:00:19.775
lại là một triển khai vector 
hóa trên nhiều ví dụ chính xác.

6
00:00:19.775 --> 00:00:25.590
Hãy cùng xem một phần của phép toán
 lan truyền trong một số ví dụ sau.

7
00:00:25.590 --> 00:00:27.645
Ví dụ là với ví dụ huấn luyện đầu tiên,

8
00:00:27.645 --> 00:00:29.130
bạn đã tính xong phép toán

9
00:00:29.130 --> 00:00:38.970
x1 cộng với b1 và sau đó
 trong ví dụ huấn luyện thứ hai,

10
00:00:38.970 --> 00:00:49.310
bạn tính xong phép toán x2 cộng với b1 và

11
00:00:49.310 --> 00:00:50.900
rồi trong ví dụ huấn luyện thứ ba,

12
00:00:50.900 --> 00:00:56.064
bạn tính xong phép toán
 x3 cộng với b1 này.

13
00:00:56.064 --> 00:01:00.930
Và để giải thích một cách đơn giản
 trên slide này, tôi sẽ bỏ qua b.

14
00:01:00.930 --> 00:01:08.395
Và để đơn giản hóa lời giải 
thích này thì giả sử b bằng 0.

15
00:01:08.395 --> 00:01:11.140
Nhưng đối số chúng ta
 sẽ đưa ra sẽ hoạt động

16
00:01:11.140 --> 00:01:14.320
khi xuất hiện một chút thay 
đổi ngay cả khi b khác không.

17
00:01:14.320 --> 00:01:17.610
Chỉ là nó sẽ giúp mô tả
 trên slide dễ hiểu hơn một chút.

18
00:01:17.610 --> 00:01:21.110
Bây giờ, w1 sẽ là một 
ma trận, đúng chứ?

19
00:01:21.110 --> 00:01:25.625
Và tôi có một số hàng
 trong ma trận này.

20
00:01:25.625 --> 00:01:28.296
Nếu bạn nhìn vào phép tính này x1,

21
00:01:28.296 --> 00:01:30.070
bạn có

22
00:01:30.070 --> 00:01:40.021
w1 nhân x1, cung cấp cho bạn một số 
vectơ cột mà bạn phải vẽ như thế này.

23
00:01:40.021 --> 00:01:47.420
Và tương tự, nếu bạn nhìn
 vào vectơ x2 này,

24
00:01:47.420 --> 00:01:54.730
bạn có w1 nhân

25
00:01:54.730 --> 00:02:00.460
x2 đưa ra một số vectơ
 cột khác, đúng chứ?

26
00:02:00.460 --> 00:02:03.250
Và nó cung cấp cho bạn z12 này.

27
00:02:03.250 --> 00:02:06.730
Và cuối cùng, nếu bạn nhìn vào x3,

28
00:02:06.730 --> 00:02:12.315
bạn có w1 nhân x3,

29
00:02:12.315 --> 00:02:19.530
cung cấp cho bạn một số 
vectơ cột thứ ba, đó là z13.

30
00:02:19.530 --> 00:02:25.250
Bây giờ, nếu bạn xem 
xét tập huấn luyện X,

31
00:02:25.250 --> 00:02:31.475
mà chúng ta hình thành bằng cách đặt tất
 cả các ví dụ huấn luyện của chúng ta cạnh nhau.

32
00:02:31.475 --> 00:02:37.010
Vì vậy, ma trận X được hình
 thành bằng cách lấy vectơ x1 và

33
00:02:37.010 --> 00:02:43.430
xếp nó theo chiều dọc
 với x2 và sau đó là x3.

34
00:02:43.430 --> 00:02:46.250
Đây là nếu chúng ta chỉ 
có ba ví dụ đào tạo.

35
00:02:46.250 --> 00:02:50.371
Nếu bạn có nhiều ví dụ hơn, thì chúng sẽ tiếp
 tục được đặt cạnh nhau theo chiều ngang như thế này.

36
00:02:50.371 --> 00:02:57.790
Nhưng nếu bây giờ bạn lấy ma trận X này
 và nhân nó với w thì cuối cùng bạn sẽ có,

37
00:02:57.790 --> 00:03:00.190
nếu bạn nghĩ về cách hoạt
 động của phép nhân ma trận, thì

38
00:03:00.190 --> 00:03:02.680
với cột đầu tiên bạn sẽ có

39
00:03:02.680 --> 00:03:06.313
những giá trị tương tự mà
 tôi đã vẽ bằng màu tím.

40
00:03:06.313 --> 00:03:10.930
Cột thứ hai sẽ là bốn giá trị tương tự.

41
00:03:10.930 --> 00:03:16.612
Và cột thứ ba sẽ là chính là
 những giá trị màu cam

42
00:03:16.612 --> 00:03:19.480
cái mà chúng sẽ chuyển thành

43
00:03:19.480 --> 00:03:27.740
Nhưng tất nhiên điều này
 chỉ bằng với z11 dưới dạng

44
00:03:27.740 --> 00:03:37.185
một vectơ cột, tiếp đến là z12 được biểu
 thị dưới dạng vectơ cột, theo sau là z13,

45
00:03:37.185 --> 00:03:39.273
cũng được biểu thị dưới 
dạng một vectơ cột.

46
00:03:39.273 --> 00:03:41.100
Và đây là nếu bạn có ba ví dụ đào tạo.

47
00:03:41.100 --> 00:03:44.255
Nếu bạn có thêm ví dụ thì
 bạn sẽ có nhiều cột hơn.

48
00:03:44.255 --> 00:03:51.220
Và như vậy, đây là ma
 trận Z1 của chúng ta.

49
00:03:51.220 --> 00:03:55.230
Và tôi hy vọng điều này giúp bạn 
hiểu tại sao trước đây chúng ta

50
00:03:55.230 --> 00:04:02.830
có w1 nhân xi bằng

51
00:04:02.830 --> 00:04:08.310
z1i khi xem xét ví dụ huấn 
luyện duy nhất tại thời điểm đó.

52
00:04:08.310 --> 00:04:12.565
Khi bạn lấy các ví dụ đào tạo khác nhau và 
xếp chúng cạnh nhau trong các cột khác nhau,

53
00:04:12.565 --> 00:04:15.250
rồi kết quả tương ứng bạn nhận được là

54
00:04:15.250 --> 00:04:18.725
z cũng được xếp cạnh nhau ở các cột.

55
00:04:18.725 --> 00:04:24.565
Và tôi sẽ không vẽ ra, nhưng bạn có thể tự
 hiểu là nếu bạn làm điều này với truyền phát Python,

56
00:04:24.565 --> 00:04:26.245
nếu bạn thêm lại

57
00:04:26.245 --> 00:04:30.534
các giá trị này b này, thì 
các giá trị vẫn đúng.

58
00:04:30.534 --> 00:04:34.540
Và thực tế là, khi bạn kết 
thúc truyền phát Python,

59
00:04:34.540 --> 00:04:41.790
cuối cùng bạn sẽ thêm b[i] cho
 từng cột của ma trận này.

60
00:04:41.790 --> 00:04:48.220
Vì vậy, trên slide này, tôi 
chỉ chứng minh rằng z1 bằng

61
00:04:48.220 --> 00:04:51.980
w1x cộng với b1 là

62
00:04:51.980 --> 00:04:54.020
một vector hóa chính xác của

63
00:04:54.020 --> 00:04:57.493
bước đầu tiên trong bốn bước
 chúng ta có trong slide trước,

64
00:04:57.493 --> 00:04:59.990
nhưng hóa ra là cũng có một
 phân tích tương tự cho phép bạn

65
00:04:59.990 --> 00:05:02.660
trình bày các bước khác
 bằng cách sử dụng

66
00:05:02.660 --> 00:05:08.105
một logic tương tự, trong đó nếu bạn xếp các
 đầu vào cạnh nhau trong các cột thì sau phương trình,

67
00:05:08.105 --> 00:05:11.510
bạn nhận được các đầu ra tương ứng cũng
 được xếp cạnh nhau nhau trong các cột.

68
00:05:11.510 --> 00:05:14.970
Cuối cùng, hãy cùng tóm lại bài học 
mà chúng ta đã nói trong video này.

69
00:05:14.970 --> 00:05:16.520
Nếu đây là mạng nơ-ron nhân tạo của bạn,

70
00:05:16.520 --> 00:05:21.693
thì chúng ta đã nói rằng đây là những gì 
bạn cần làm nếu bạn thực hiện bước truyền xuôi,

71
00:05:21.693 --> 00:05:27.693
một ví dụ huấn luyện tại một thời điểm đi 
từ i bằng 1 đến m. Và sau đó chúng ta nói,

72
00:05:27.693 --> 00:05:34.100
hãy xếp các ví dụ đào tạo cạnh nhau trong 
các cột như vậy và với mỗi giá trị z1,

73
00:05:34.100 --> 00:05:38.265
a1, z2, a2 này, hãy xếp các cột 
tương ứng cạnh nhau như sau.

74
00:05:38.265 --> 00:05:43.820
Đây là một ví dụ cho a1 
nhưng cũng đúng với z1,

75
00:05:43.820 --> 00:05:46.975
a1, z2 và a2.

76
00:05:46.975 --> 00:05:51.090
Sau đó, trên slide trước đó,
 chúng ta đã trình bày là

77
00:05:51.090 --> 00:05:58.785
dòng này cho phép bạn vector hóa điều
 này trên tất cả m các ví dụ cùng một lúc.

78
00:05:58.785 --> 00:06:00.555
Và với lý do tương tự,

79
00:06:00.555 --> 00:06:03.880
bạn có thể chỉ ra rằng
 tất cả các dòng khác là

80
00:06:03.880 --> 00:06:08.811
vector hóa chính xác của 
cả bốn dòng mã này.

81
00:06:08.811 --> 00:06:10.675
Và hãy nhớ là,

82
00:06:10.675 --> 00:06:18.960
bởi vì x cũng bằng a0 vì bạn hãy nhớ rằng

83
00:06:18.960 --> 00:06:27.980
vectơ đặc trưng đầu vào x
 bằng a0, do đó xi bằng a0i.

84
00:06:27.980 --> 00:06:30.870
Và thực sự thì có một phép 
đối xứng nhất định để

85
00:06:30.870 --> 00:06:34.110
những phương trình mà trong đó,
 phương trình đầu tiên này cũng có thể là

86
00:06:34.110 --> 00:06:41.790
viết z1 bằng w1 a0 cộng với b1.

87
00:06:41.790 --> 00:06:45.680
Và do đó, bạn thấy rằng
 cặp phương trình này và cặp

88
00:06:45.680 --> 00:06:51.805
phương trình này trông rất giống nhau
 nhưng chỉ là tất cả các chỉ số tăng lên một.

89
00:06:51.805 --> 00:06:55.880
Vì vậy, điều này cho thấy các lớp khác 
nhau của mạng nơ-ron nhân tạo thì

90
00:06:55.880 --> 00:07:00.585
gần như là làm điều giống nhau hoặc
 làm cùng một phép toán lặp đi lặp lại.

91
00:07:00.585 --> 00:07:04.220
Và ở đây chúng ta có mạng nơ-ron
 nhân tạo hai lớp và chúng ta sẽ học về

92
00:07:04.220 --> 00:07:08.475
một mạng nơ-ron nhân tạo sâu hơn 
nhiều trong các video của tuần tới.

93
00:07:08.475 --> 00:07:11.670
Bạn sẽ thấy rằng về cơ bản, kể cả các
 mạng nơ-ron sâu hơn cũng thực hiện

94
00:07:11.670 --> 00:07:16.215
hai bước này nhưng sẽ thực 
hiện chúng nhiều lần hơn.

95
00:07:16.215 --> 00:07:21.255
Và đó là cách bạn có thể vector hóa mạng 
nơ-ron nhân tạo qua nhiều ví dụ huấn luyện.

96
00:07:21.255 --> 00:07:25.590
Cho đến nay chúng ta đã sử dụng các hàm
 sigmoid trên khắp các mạng nơ-ron nhân tạo.

97
00:07:25.590 --> 00:07:27.925
Nhưng trên thực tế, đó không 
phải là sự lựa chọn tốt nhất.

98
00:07:27.925 --> 00:07:29.675
Trong video tiếp theo, hãy cùng tìm hiểu kỹ

99
00:07:29.675 --> 00:07:32.450
hơn nữa về cách bạn có thể
 sử dụng các hàm kích hoạt

100
00:07:32.450 --> 00:07:37.190
khác nhau, trong đó chức năng sigmoid 
chỉ là một lựa chọn có thể chấp nhận được.