WEBVTT

1
00:00:00.620 --> 00:00:03.610
Là

2
00:00:07.590 --> 00:00:11.658
một phần của khóa học này của deeplearning.ai, tôi hy vọng sẽ không chỉ dạy cho bạn những ý tưởng kỹ thuật trong deep learning, mà còn giới thiệu bạn với một số người, một số anh hùng trong deep learning.

3
00:00:11.658 --> 00:00:13.160
Những người đã phát minh ra rất

4
00:00:13.160 --> 00:00:17.700
nhiều ý tưởng này mà bạn tìm hiểu trong khóa học này hoặc trong chuyên ngành này.

5
00:00:17.700 --> 00:00:21.420
Trong những video này, tôi cũng hy vọng sẽ yêu cầu các nhà lãnh đạo đào tạo sâu này cung cấp

6
00:00:21.420 --> 00:00:24.990
cho bạn lời khuyên nghề nghiệp về cách bạn có thể đột nhập vào học sâu, về

7
00:00:24.990 --> 00:00:27.805
cách bạn có thể nghiên cứu hoặc tìm một công việc trong học sâu.

8
00:00:27.805 --> 00:00:30.156
Là phần đầu tiên của loạt bài phỏng vấn này,

9
00:00:30.156 --> 00:00:34.228
tôi rất vui mừng giới thiệu với bạn một cuộc phỏng vấn với Geoffrey Hinton.

10
00:00:38.427 --> 00:00:44.150
Chào mừng Geoff, và cảm ơn bạn đã thực hiện cuộc phỏng vấn này với deeplearning.ai.

11
00:00:44.150 --> 00:00:46.550
Cảm ơn bạn đã mời tôi.

12
00:00:46.550 --> 00:00:50.088
Tôi nghĩ rằng tại thời điểm này, bạn hơn bất kỳ ai khác trên hành tinh này đã

13
00:00:50.088 --> 00:00:52.835
phát minh ra rất nhiều ý tưởng đằng sau việc học sâu.

14
00:00:52.835 --> 00:00:57.650
Và rất nhiều người đã gọi bạn là cha đỡ đầu của việc học sâu.

15
00:00:57.650 --> 00:01:01.529
Mặc dù phải đến khi chúng tôi trò chuyện vài phút trước, cho đến khi tôi nhận ra

16
00:01:01.529 --> 00:01:05.600
bạn nghĩ rằng tôi là người đầu tiên gọi bạn như vậy, điều mà tôi khá vui vì đã làm được.

17
00:01:06.780 --> 00:01:11.320
Nhưng điều tôi muốn hỏi là, nhiều người biết bạn như một huyền thoại,

18
00:01:11.320 --> 00:01:15.030
tôi muốn hỏi về câu chuyện cá nhân của bạn đằng sau huyền thoại.

19
00:01:15.030 --> 00:01:19.980
Vậy làm thế nào bạn đã tham gia vào, quay trở lại đây, làm thế nào bạn tham gia vào AI và

20
00:01:19.980 --> 00:01:21.520
học máy và mạng nơ-ron?

21
00:01:22.730 --> 00:01:26.960
Vì vậy, khi tôi học trung học, tôi có một người bạn cùng lớp luôn giỏi

22
00:01:26.960 --> 00:01:31.220
hơn tôi trong mọi thứ, anh ấy là một nhà toán học xuất sắc.

23
00:01:31.220 --> 00:01:37.010
Và một ngày nọ, anh ấy đến trường và nói, bạn có biết bộ não sử dụng hình ba chiều không?

24
00:01:38.190 --> 00:01:44.161
Và tôi đoán đó là khoảng năm 1966, và tôi nói, hình ba chiều là gì?

25
00:01:44.161 --> 00:01:47.390
Và anh ấy giải thích rằng trong một hình ba chiều, bạn có thể cắt một nửa của nó, và

26
00:01:47.390 --> 00:01:49.730
bạn vẫn có được toàn bộ bức tranh.

27
00:01:49.730 --> 00:01:53.466
Và những ký ức trong não có thể được phân phối trên toàn bộ não.

28
00:01:53.466 --> 00:01:56.022
Và vì vậy tôi đoán anh ấy đã đọc về các thí nghiệm của Lashley,

29
00:01:56.022 --> 00:01:57.939
nơi bạn cắt bỏ những mảnh não của chuột và phát hiện

30
00:01:57.939 --> 00:02:01.740
ra rằng rất khó để tìm thấy một chút nơi nó lưu trữ một bộ nhớ cụ thể.

31
00:02:04.411 --> 00:02:08.920
Vì vậy, đó là điều đầu tiên khiến tôi quan tâm đến việc bộ não lưu trữ ký ức như thế nào.

32
00:02:10.180 --> 00:02:12.220
Và sau đó khi tôi vào đại học,

33
00:02:12.220 --> 00:02:15.130
tôi bắt đầu học sinh lý và vật lý.

34
00:02:16.400 --> 00:02:17.731
Tôi nghĩ khi tôi còn ở Cambridge,

35
00:02:17.731 --> 00:02:20.260
tôi là sinh viên đại học duy nhất chuyên ngành sinh lý học và vật lý.

36
00:02:21.888 --> 00:02:25.270
Và sau đó tôi từ bỏ điều đó và

37
00:02:25.270 --> 00:02:29.170
cố gắng làm triết học, bởi vì tôi nghĩ điều đó có thể giúp tôi hiểu rõ hơn.

38
00:02:29.170 --> 00:02:32.780
Nhưng đối với tôi, điều đó dường như thực sự

39
00:02:32.780 --> 00:02:37.130
thiếu cách phân biệt khi họ nói điều gì đó sai.

40
00:02:37.130 --> 00:02:39.420
Và sau đó tôi chuyển sang tâm lý học.

41
00:02:41.988 --> 00:02:45.920
Và trong tâm lý học, họ có những lý thuyết rất, rất đơn giản, và đối với tôi, dường như

42
00:02:45.920 --> 00:02:49.620
nó không đủ để giải thích những gì bộ não đang làm.

43
00:02:49.620 --> 00:02:52.737
Vì vậy, sau đó tôi nghỉ một thời gian và trở thành một thợ mộc.

44
00:02:52.737 --> 00:02:57.169
Và sau đó tôi quyết định thử AI, và đến Edinburgh,

45
00:02:57.169 --> 00:02:59.580
để học AI với Langer Higgins.

46
00:02:59.580 --> 00:03:02.662
Và anh ấy đã làm rất tốt công việc trên mạng nơ-ron, và

47
00:03:02.662 --> 00:03:07.830
anh ấy đã từ bỏ mạng nơ-ron, và rất ấn tượng với luận án của Winograd.

48
00:03:07.830 --> 00:03:11.460
Vì vậy, khi tôi đến, anh ấy nghĩ rằng tôi đang làm những thứ kiểu cũ này, và

49
00:03:11.460 --> 00:03:14.210
tôi nên bắt đầu với AI tượng trưng.

50
00:03:14.210 --> 00:03:18.210
Và chúng tôi đã có rất nhiều cuộc chiến về điều đó, nhưng tôi vẫn tiếp tục làm những gì tôi tin tưởng.

51
00:03:18.210 --> 00:03:21.138
Và sau đó thì sao?

52
00:03:21.138 --> 00:03:28.033
Cuối cùng tôi đã lấy bằng tiến sĩ về AI, và sau đó tôi không thể kiếm được việc làm ở Anh.

53
00:03:28.033 --> 00:03:30.979
Nhưng tôi đã thấy quảng cáo rất hay này cho

54
00:03:30.979 --> 00:03:36.070
Học bổng Sloan ở California, và tôi đã tìm được một trong số đó.

55
00:03:36.070 --> 00:03:40.625
Và tôi đã đến California, và mọi thứ ở đó đã khác.

56
00:03:40.625 --> 00:03:46.685
Vì vậy, ở Anh, mạng lưới thần kinh được coi là ngớ ngẩn,

57
00:03:46.685 --> 00:03:50.272
và ở California, Don Norman và

58
00:03:50.272 --> 00:03:56.640
David Rumelhart rất cởi mở với những ý tưởng về mạng nơ-ron.

59
00:03:56.640 --> 00:04:00.720
Đó là lần đầu tiên tôi đến một nơi mà suy nghĩ về cách thức hoạt động của bộ não

60
00:04:00.720 --> 00:04:03.290
và suy nghĩ về việc điều đó có thể liên quan đến tâm lý học

61
00:04:03.290 --> 00:04:05.650
như thế nào, được coi là một điều rất tích cực.

62
00:04:05.650 --> 00:04:06.936
Và thật thú vị

63
00:04:06.936 --> 00:04:09.792
ở đó, đặc biệt là hợp tác với David Rumelhart thật tuyệt vời.

64
00:04:09.792 --> 00:04:12.968
Tôi hiểu rồi, tuyệt. Vì vậy, đây là khi bạn ở UCSD, và

65
00:04:12.968 --> 00:04:16.177
bạn và Rumelhart vào khoảng năm 1982, cuối cùng đã

66
00:04:16.177 --> 00:04:20.182
viết một tờ giấy có ý nghĩa, phải không?

67
00:04:20.182 --> 00:04:23.292
Trên thực tế, nó phức tạp hơn thế.

68
00:04:23.292 --> 00:04:24.796
Chuyện gì đã xảy ra?

69
00:04:24.796 --> 00:04:28.214
Tôi nghĩ vào đầu năm 1982,

70
00:04:28.214 --> 00:04:32.900
David Rumelhart và tôi, và Ron Williams,

71
00:04:32.900 --> 00:04:37.967
giữa chúng tôi đã phát triển thuật toán backprop, đó

72
00:04:37.967 --> 00:04:42.291
chủ yếu là ý tưởng của David Rumelhart. Sau

73
00:04:42.291 --> 00:04:46.390
đó chúng tôi phát hiện ra rằng nhiều người khác đã phát minh ra nó.

74
00:04:46.390 --> 00:04:52.798
David Parker đã phát minh ra nó, có lẽ sau chúng tôi, nhưng trước khi chúng tôi xuất bản.

75
00:04:52.798 --> 00:04:56.425
Paul Werbos đã xuất bản nó khá nhiều năm trước đó, nhưng

76
00:04:56.425 --> 00:04:58.860
không ai chú ý nhiều đến nó.

77
00:04:58.860 --> 00:05:01.923
Và có những người khác đã phát triển các thuật toán rất giống

78
00:05:01.923 --> 00:05:04.340
nhau, không rõ nghĩa là gì từ backprop.

79
00:05:04.340 --> 00:05:08.055
Nhưng sử dụng quy tắc chuỗi để có được các dẫn xuất không phải là một ý tưởng mới lạ.

80
00:05:08.055 --> 00:05:12.484
Tôi hiểu, tại sao bạn nghĩ rằng chính bài báo của bạn đã giúp

81
00:05:12.484 --> 00:05:15.940
cộng đồng bám vào backprop đến vậy?

82
00:05:15.940 --> 00:05:20.540
Có cảm giác như bài báo của bạn đã đánh dấu sự lây nhiễm trong việc chấp nhận

83
00:05:20.540 --> 00:05:22.934
thuật toán này, bất kể ai chấp nhận nó.

84
00:05:22.934 --> 00:05:26.675
Vì vậy, chúng tôi đã tìm được một bài báo về Thiên nhiên vào năm 1986.

85
00:05:26.675 --> 00:05:30.580
Và tôi đã làm khá nhiều công việc chính trị để bài báo được chấp nhận.

86
00:05:30.580 --> 00:05:34.622
Tôi nhận ra rằng một trong những trọng tài có lẽ sẽ là Stuart Sutherland,

87
00:05:34.622 --> 00:05:36.992
một nhà tâm lý học nổi tiếng ở Anh.

88
00:05:36.992 --> 00:05:38.815
Và tôi đã đến nói chuyện với anh ấy trong một thời gian dài, và

89
00:05:38.815 --> 00:05:41.480
giải thích cho anh ấy chính xác những gì đang xảy ra.

90
00:05:41.480 --> 00:05:44.140
Và anh ấy rất ấn tượng bởi thực tế là

91
00:05:44.140 --> 00:05:48.970
chúng tôi đã chỉ ra rằng backprop có thể học cách biểu diễn cho các từ.

92
00:05:48.970 --> 00:05:52.490
Và bạn có thể nhìn vào những biểu diễn đó, là những vectơ nhỏ,

93
00:05:52.490 --> 00:05:55.950
và bạn có thể hiểu ý nghĩa của các đặc điểm riêng lẻ.

94
00:05:55.950 --> 00:06:01.600
Vì vậy, chúng tôi thực sự đã đào tạo nó bằng ba từ nhỏ về cây phả hệ,

95
00:06:01.600 --> 00:06:06.420
giống như Mary có mẹ Victoria.

96
00:06:06.420 --> 00:06:11.550
Và bạn sẽ cho nó hai từ đầu tiên, và nó sẽ phải dự đoán từ cuối cùng.

97
00:06:11.550 --> 00:06:12.970
Và sau khi bạn đào tạo nó,

98
00:06:12.970 --> 00:06:17.780
bạn có thể thấy tất cả các loại đặc điểm trong biểu diễn của các từ riêng lẻ.

99
00:06:17.780 --> 00:06:19.950
Giống như quốc tịch của người

100
00:06:19.950 --> 00:06:25.180
ở đó, họ thuộc thế hệ nào, họ thuộc nhánh nào của cây gia đình, v.v.

101
00:06:25.180 --> 00:06:27.680
Đó là điều khiến Stuart Sutherland thực sự ấn tượng với nó, và

102
00:06:27.680 --> 00:06:29.666
tôi nghĩ đó là lý do tại sao bài báo được chấp nhận. Việc

103
00:06:29.666 --> 00:06:33.905
nhúng từ rất sớm và bạn đã thấy các đặc điểm đã học được

104
00:06:33.905 --> 00:06:38.390
của ý nghĩa ngữ nghĩa xuất hiện từ thuật toán đào tạo.

105
00:06:38.390 --> 00:06:44.090
Vâng, vì vậy theo quan điểm của một nhà tâm lý học, điều thú vị là nó thống nhất

106
00:06:44.090 --> 00:06:49.740
hai chuỗi ý tưởng hoàn toàn khác nhau về kiến thức là như thế nào.

107
00:06:49.740 --> 00:06:53.460
Vì vậy, có quan điểm của nhà tâm lý học cũ rằng một khái niệm chỉ là một

108
00:06:53.460 --> 00:06:56.810
bó lớn các tính năng, và có rất nhiều bằng chứng cho điều đó.

109
00:06:56.810 --> 00:07:02.180
Và sau đó là quan điểm AI vào thời điểm đó, đó là một quan điểm cấu trúc chính thức.

110
00:07:02.180 --> 00:07:06.190
Đó là một khái niệm là cách nó liên quan đến các khái niệm khác.

111
00:07:06.190 --> 00:07:09.820
Và để nắm bắt một khái niệm, bạn sẽ phải làm một cái gì đó như cấu trúc đồ thị hoặc

112
00:07:09.820 --> 00:07:11.640
có thể là một mạng ngữ nghĩa.

113
00:07:11.640 --> 00:07:15.875
Và ví dụ truyền ngược này cho thấy, bạn có thể cung cấp cho nó

114
00:07:15.875 --> 00:07:21.070
thông tin sẽ đi vào cấu trúc biểu đồ, hoặc trong trường hợp này là cây gia phả.

115
00:07:22.080 --> 00:07:26.920
Và nó có thể chuyển đổi thông tin đó thành các tính năng theo cách mà sau đó nó có thể

116
00:07:26.920 --> 00:07:33.470
sử dụng các tính năng để lấy thông tin nhất quán mới, tức là khái quát hóa.

117
00:07:33.470 --> 00:07:38.438
Nhưng điều quan trọng là điều này đi qua lại giữa biểu diễn đồ họa hoặc biểu diễn có

118
00:07:38.438 --> 00:07:43.000
cấu trúc cây của cây phả hệ và sự đại

119
00:07:43.000 --> 00:07:46.715
diện của con người dưới dạng vectơ đặc điểm lớn.

120
00:07:46.715 --> 00:07:50.873
Và trên thực tế, từ biểu diễn giống như đồ thị, bạn có thể nhận được các vect

121
00:07:50.873 --> 00:07:51.469
ơ tính năng.

122
00:07:51.469 --> 00:07:54.995
Và từ các vectơ tính năng, bạn có thể nhận được nhiều biểu diễn giống như đồ thị hơn.

123
00:07:54.995 --> 00:07:57.730
Đây là năm 1986?

124
00:07:57.730 --> 00:08:02.430
Vào đầu những năm 90, Bengio đã chỉ ra rằng bạn thực sự có thể lấy dữ liệu thực,

125
00:08:02.430 --> 00:08:07.420
bạn có thể lấy văn bản tiếng Anh và áp dụng các kỹ thuật tương tự ở đó, và có thể

126
00:08:07.420 --> 00:08:13.980
nhúng các từ thực từ văn bản tiếng Anh, và điều đó gây ấn tượng với mọi người rất nhiều.

127
00:08:13.980 --> 00:08:18.682
Tôi đoán gần đây chúng ta đã nói rất nhiều về tốc độ các máy tính như GPU và

128
00:08:18.682 --> 00:08:21.750
siêu máy tính thúc đẩy việc học sâu.

129
00:08:21.750 --> 00:08:26.376
Tôi không nhận ra rằng từ năm 1986 đến đầu những năm 90, có vẻ như giữa

130
00:08:26.376 --> 00:08:29.570
bạn và Benjio đã có sự khởi đầu của xu hướng này.

131
00:08:30.600 --> 00:08:32.630
Vâng, đó là một bước tiến lớn.

132
00:08:32.630 --> 00:08:41.440
Vào năm 1986, tôi đã sử dụng một máy danh sách ít hơn một phần mười của một mega flop.

133
00:08:41.440 --> 00:08:47.720
Và vào khoảng năm 1993 hoặc khoảng đó, mọi người đã chứng kiến mười vụ thất bại lớn.

134
00:08:47.720 --> 00:08:49.600
Tôi hiểu rồi. Vì vậy, có hệ số 100,

135
00:08:49.600 --> 00:08:51.770
và đó là điểm dễ sử dụng,

136
00:08:51.770 --> 00:08:53.580
bởi vì máy tính ngày càng nhanh hơn.

137
00:08:53.580 --> 00:08:56.960
Trong vài thập kỷ qua, bạn đã phát minh ra rất

138
00:08:56.960 --> 00:08:59.970
nhiều phần mạng nơ-ron và học sâu.

139
00:08:59.970 --> 00:09:02.670
Tôi thực sự tò mò, trong tất cả những thứ bạn đã phát minh ra,

140
00:09:02.670 --> 00:09:05.050
cái nào trong số những thứ bạn vẫn hào hứng nhất ngày nay?

141
00:09:06.940 --> 00:09:09.590
Vì vậy, tôi nghĩ điều đẹp nhất là công việc tôi làm với

142
00:09:09.590 --> 00:09:12.620
Terry Sejnowski trên máy Boltzmann.

143
00:09:12.620 --> 00:09:14.500
Vì vậy, chúng tôi phát hiện ra

144
00:09:14.500 --> 00:09:18.830
rằng có một thuật toán học thực sự rất đơn giản áp dụng cho các

145
00:09:18.830 --> 00:09:23.550
mạng kết nối mật độ lớn, nơi bạn chỉ có thể nhìn thấy một vài nút.

146
00:09:23.550 --> 00:09:27.730
Vì vậy, nó sẽ học các biểu diễn ẩn và đó là một thuật toán rất đơn giản.

147
00:09:27.730 --> 00:09:31.130
Và nó trông giống như loại thứ mà bạn có thể nhận được trong não vì

148
00:09:31.130 --> 00:09:34.210
mỗi khớp thần kinh chỉ cần biết về hành vi của hai

149
00:09:34.210 --> 00:09:35.940
tế bào thần kinh mà nó được kết nối trực tiếp.

150
00:09:37.010 --> 00:09:41.230
Và thông tin được truyền bá là như nhau.

151
00:09:41.230 --> 00:09:45.160
Có hai giai đoạn khác nhau, chúng tôi gọi là thức và ngủ.

152
00:09:45.160 --> 00:09:46.820
Nhưng trong hai giai đoạn khác nhau,

153
00:09:46.820 --> 00:09:48.760
bạn đang truyền thông tin theo cùng một cách.

154
00:09:48.760 --> 00:09:52.360
Trong đó như trong một cái gì đó như truyền ngược, có một đường chuyền tiến và

155
00:09:52.360 --> 00:09:54.820
một đường chuyền lùi, và chúng hoạt động khác nhau.

156
00:09:54.820 --> 00:09:56.379
Họ đang gửi nhiều loại tín hiệu khác nhau.

157
00:09:58.100 --> 00:10:01.190
Vì vậy, tôi nghĩ đó là điều đẹp nhất.

158
00:10:01.190 --> 00:10:03.730
Và trong nhiều năm, nó trông giống như một sự tò mò,

159
00:10:03.730 --> 00:10:05.090
bởi vì nó có vẻ như nó quá chậm.

160
00:10:06.210 --> 00:10:10.420
Nhưng sau đó, tôi đã loại bỏ một chút vẻ đẹp, và nó bắt đầu khiến

161
00:10:10.420 --> 00:10:13.730
tôi ổn định và chỉ sử dụng một lần lặp lại, trong một mạng lưới hơi đơn giản hơn.

162
00:10:13.730 --> 00:10:16.570
Và điều đó đã khiến máy Boltzmann bị hạn chế, thực sự

163
00:10:16.570 --> 00:10:19.430
hoạt động hiệu quả trong thực tế.

164
00:10:19.430 --> 00:10:21.586
Vì vậy, trong cuộc thi Netflix, ví dụ,

165
00:10:21.586 --> 00:10:26.170
máy Boltzmann bị hạn chế là một trong những thành phần của bài dự thi chiến thắng.

166
00:10:26.170 --> 00:10:30.210
Và trên thực tế, phần lớn sự hồi sinh gần đây của mạng nơ-ron và

167
00:10:30.210 --> 00:10:34.790
học sâu, bắt đầu từ khoảng năm 2007, là cỗ máy Boltzmann bị hạn chế, và làm hỏng công việc máy Boltz

168
00:10:34.790 --> 00:10:37.710
mann mà bạn và phòng thí nghiệm của bạn đã làm.

169
00:10:38.940 --> 00:10:42.130
Vâng, vì vậy đó là một trong những công việc khác mà tôi rất hài lòng,

170
00:10:42.130 --> 00:10:46.290
ý tưởng rằng bạn có thể đào tạo máy Boltzmann bị hạn chế của mình, chỉ

171
00:10:46.290 --> 00:10:51.120
có một lớp tính năng ẩn và bạn có thể học một lớp tính năng.

172
00:10:51.120 --> 00:10:54.850
Và sau đó bạn có thể coi các tính năng đó là dữ liệu và làm lại, và

173
00:10:54.850 --> 00:10:57.953
sau đó bạn có thể coi các tính năng mới bạn đã học là dữ liệu và làm lại,

174
00:10:57.953 --> 00:10:59.570
bao nhiêu lần tùy thích.

175
00:10:59.570 --> 00:11:03.060
Vì vậy, điều đó thật tuyệt, nó đã hoạt động trong thực tế.

176
00:11:03.060 --> 00:11:08.709
Và rồi UY Tây nhận ra rằng toàn bộ sự việc có thể được coi như một mô hình duy nhất,

177
00:11:08.709 --> 00:11:11.110
nhưng đó là một kiểu mẫu kỳ lạ.

178
00:11:11.110 --> 00:11:15.946
Đó là một mô hình mà ở trên cùng bạn có một cỗ máy Boltzmann hạn chế, nhưng

179
00:11:15.946 --> 00:11:20.626
bên dưới đó bạn có một mạng lưới tín ngưỡng Sigmoid, thứ được

180
00:11:20.626 --> 00:11:23.060
phát minh ra sớm từ nhiều năm.

181
00:11:23.060 --> 00:11:24.620
Vì vậy, đó là một mô hình có định hướng và những

182
00:11:24.620 --> 00:11:28.651
gì chúng tôi đã tìm ra bằng cách đào tạo những

183
00:11:28.651 --> 00:11:32.760
máy Boltzmann bị hạn chế này là một cách hiệu quả để suy luận trong mạng lưới tín ngưỡng Sigmoid.

184
00:11:33.830 --> 00:11:36.870
Vì vậy, vào khoảng thời gian đó,

185
00:11:36.870 --> 00:11:41.270
có những người làm mạng nơ-ron, những người sẽ sử dụng các mạng kết nối dày đặc, nhưng

186
00:11:41.270 --> 00:11:45.500
không có bất kỳ cách nào tốt để tạo dấu ấn xác suất trong chúng.

187
00:11:45.500 --> 00:11:50.050
Và bạn đã có những người làm mô hình đồ họa, không giống như các con tôi, những

188
00:11:50.050 --> 00:11:55.603
người có thể suy luận đúng cách, nhưng chỉ trong các mạng lưới kết nối thưa thớt.

189
00:11:55.603 --> 00:12:01.140
Và những gì chúng tôi cố gắng chỉ ra là cách học những mạng

190
00:12:01.140 --> 00:12:06.280
lưới niềm tin sâu sắc này để có một hình thức suy luận gần đúng rất nhanh,

191
00:12:06.280 --> 00:12:10.578
đó chỉ là bàn tay trong một đường chuyền và đó là một kết quả rất đẹp.

192
00:12:10.578 --> 00:12:14.890
Và bạn có thể đảm bảo rằng mỗi khi bạn học thêm lớp tính năng

193
00:12:16.010 --> 00:12:19.980
đó sẽ có một ban nhạc, mỗi lần bạn học một lớp mới, bạn có một ban nhạc

194
00:12:19.980 --> 00:12:22.700
mới, và ban nhạc mới luôn tốt hơn ban nhạc cũ.

195
00:12:22.700 --> 00:12:25.810
Các dải biến thể, hiển thị khi bạn thêm các lớp.

196
00:12:25.810 --> 00:12:26.970
Vâng, tôi nhớ video đó.

197
00:12:26.970 --> 00:12:29.680
Vì vậy, đó là điều thứ hai mà tôi thực sự hào hứng.

198
00:12:29.680 --> 00:12:35.600
Và tôi đoán điều thứ ba là công việc tôi đã làm trên các phương pháp biến thể.

199
00:12:35.600 --> 00:12:40.750
Hóa ra những người trong số liệu thống kê đã làm công việc tương tự trước đó,

200
00:12:40.750 --> 00:12:43.100
nhưng chúng tôi không biết về điều đó.

201
00:12:44.610 --> 00:12:47.260
Vì vậy, chúng tôi đã cố

202
00:12:47.260 --> 00:12:50.250
gắng làm cho EN hoạt động tốt hơn rất nhiều bằng cách cho thấy bạn không cần phải thực hiện một bước E hoàn hảo.

203
00:12:50.250 --> 00:12:52.800
Bạn có thể thực hiện một bước E gần đúng.

204
00:12:52.800 --> 00:12:55.320
Và EN là một thuật toán lớn trong thống kê.

205
00:12:55.320 --> 00:12:58.380
Và chúng tôi đã cho thấy một sự khái quát lớn về nó.

206
00:12:58.380 --> 00:13:02.490
Và đặc biệt, vào năm 1993, tôi đoán, với Van Camp.

207
00:13:02.490 --> 00:13:07.040
Tôi đã làm một bài báo, với tôi nghĩ, bài báo Bayes biến thể đầu tiên, trong đó

208
00:13:07.040 --> 00:13:12.090
chúng tôi chỉ ra rằng bạn thực sự có thể thực hiện một phiên bản học Bayes dễ hiểu

209
00:13:12.090 --> 00:13:17.950
hơn nhiều, bằng cách xấp xỉ phần sau thực sự với

210
00:13:17.950 --> 00:13:20.320
a. Và bạn có thể làm điều đó trong mạng thần kinh.

211
00:13:20.320 --> 00:13:22.600
Và tôi đã rất phấn khích vì điều đó.

212
00:13:22.600 --> 00:13:23.680
Tôi hiểu rồi. Wow, đúng rồi.

213
00:13:23.680 --> 00:13:26.670
Vâng, tôi nghĩ rằng tôi nhớ tất cả các giấy tờ này.

214
00:13:26.670 --> 00:13:32.630
Bạn và Hinton, gần như Paper, đã dành nhiều giờ để đọc về điều đó.

215
00:13:32.630 --> 00:13:36.070
Và tôi nghĩ một số thuật toán bạn sử dụng ngày nay, hoặc

216
00:13:36.070 --> 00:13:41.110
một số thuật toán mà rất nhiều người sử dụng gần như hàng ngày, là những

217
00:13:41.110 --> 00:13:46.570
thứ như bỏ học, hoặc tôi đoán kích hoạt ReLU đến từ nhóm của bạn?

218
00:13:46.570 --> 00:13:47.390
Có và không.

219
00:13:47.390 --> 00:13:51.470
Vì vậy, những người khác đã nghĩ về các đơn vị tuyến tính chỉnh lưu.

220
00:13:51.470 --> 00:13:56.860
Và chúng tôi thực sự đã thực hiện một số công việc với các máy Boltzmann hạn chế

221
00:13:56.860 --> 00:14:02.880
cho thấy ReLU gần như tương đương với toàn bộ các đơn vị hậu cần.

222
00:14:02.880 --> 00:14:05.190
Và đó là một trong những điều đã giúp RelU bắt kịp.

223
00:14:05.190 --> 00:14:07.440
Tôi thực sự tò mò về điều đó.

224
00:14:07.440 --> 00:14:12.570
Bài báo giá trị có rất nhiều toán học cho thấy hàm này có

225
00:14:12.570 --> 00:14:15.530
thể được xấp xỉ với công thức thực sự phức tạp này.

226
00:14:15.530 --> 00:14:19.140
Bạn đã làm toán đó để bài báo của bạn được chấp nhận vào một hội nghị học thuật,

227
00:14:19.140 --> 00:14:24.840
hay tất cả toán học đó thực sự ảnh hưởng đến sự phát triển của tối đa 0 và x?

228
00:14:26.450 --> 00:14:30.440
Đó là một trong những trường hợp mà toán học thực sự quan trọng đối

229
00:14:30.440 --> 00:14:32.350
với sự phát triển của ý tưởng.

230
00:14:32.350 --> 00:14:35.262
Vì vậy, tôi biết về các đơn vị tuyến tính chỉnh lưu, rõ ràng, và

231
00:14:35.262 --> 00:14:36.821
tôi biết về các đơn vị logistic.

232
00:14:36.821 --> 00:14:39.250
Và vì công việc trên máy Boltzmann,

233
00:14:39.250 --> 00:14:42.720
tất cả các công việc cơ bản được thực hiện bằng cách sử dụng các đơn vị hậu cần.

234
00:14:42.720 --> 00:14:45.120
Và vì vậy câu hỏi đặt ra là,

235
00:14:45.120 --> 00:14:49.070
thuật toán học có thể hoạt động trong một cái gì đó với các đơn vị tuyến tính chỉnh lưu không?

236
00:14:49.070 --> 00:14:54.400
Và bằng cách

237
00:14:54.400 --> 00:15:00.350
cho thấy các đơn vị tuyến tính chỉnh lưu gần như tương đương chính xác với một chồng đơn vị logistic, chúng tôi đã chỉ ra rằng tất cả các phép toán sẽ được thực hiện.

238
00:15:00.350 --> 00:15:01.508
Tôi hiểu rồi.

239
00:15:01.508 --> 00:15:05.890
Và nó đã cung cấp nguồn cảm hứng cho ngày hôm nay, rất nhiều người sử dụng ReLU và

240
00:15:05.890 --> 00:15:08.000
nó chỉ hoạt động mà không cần- Vâng.

241
00:15:08.000 --> 00:15:12.130
Không nhất thiết phải hiểu cùng một động lực.

242
00:15:13.150 --> 00:15:16.850
Vâng, một điều tôi nhận thấy sau đó khi tôi truy cập Google.

243
00:15:16.850 --> 00:15:22.796
Tôi đoán vào năm 2014, tôi đã nói chuyện tại Google về việc sử dụng RelU và

244
00:15:22.796 --> 00:15:26.660
khởi tạo với ma trận nhận dạng.

245
00:15:26.660 --> 00:15:30.300
bởi vì điều tốt đẹp về RelU là nếu bạn tiếp tục sao chép các

246
00:15:30.300 --> 00:15:32.667
lớp ẩn và bạn khởi tạo với danh tính,

247
00:15:32.667 --> 00:15:35.050
nó chỉ sao chép mẫu trong lớp bên dưới.

248
00:15:36.140 --> 00:15:40.120
Và vì vậy tôi đã chỉ ra rằng bạn có thể đào tạo mạng với 300 lớp ẩn và

249
00:15:40.120 --> 00:15:44.760
bạn có thể đào tạo chúng thực sự hiệu quả nếu bạn khởi tạo với danh tính của chúng.

250
00:15:44.760 --> 00:15:48.065
Nhưng tôi đã không theo đuổi điều đó thêm nữa và tôi thực sự hối hận vì đã không theo đuổi điều đó.

251
00:15:48.065 --> 00:15:52.507
Chúng tôi đã xuất bản một bài báo cho thấy bạn có thể khởi tạo một hoạt động cho

252
00:15:52.507 --> 00:15:55.565
thấy bạn có thể khởi tạo tính lặp lại như vậy.

253
00:15:55.565 --> 00:16:00.370
Nhưng tôi nên theo đuổi nó hơn nữa bởi vì Later on the

254
00:16:00.370 --> 00:16:03.572
network này thực sự là kiểu như vậy.

255
00:16:03.572 --> 00:16:06.660
Trong những năm qua, tôi đã nghe bạn nói rất nhiều về bộ não.

256
00:16:06.660 --> 00:16:09.447
Tôi đã nghe bạn nói về mối quan hệ là hậu quả và bộ não.

257
00:16:09.447 --> 00:16:13.720
Suy nghĩ hiện tại của bạn về điều đó là gì?

258
00:16:13.720 --> 00:16:16.910
Tôi thực sự đang làm một bài báo về điều đó ngay bây giờ.

259
00:16:18.250 --> 00:16:21.160
Tôi đoán suy nghĩ chính của tôi là điều này.

260
00:16:21.160 --> 00:16:25.570
Nếu hóa ra đạo cụ phía sau là một thuật toán thực sự tốt để thực hiện việc học.

261
00:16:26.620 --> 00:16:31.610
Sau đó, chắc chắn sự tiến hóa có thể tìm ra cách thực hiện nó.

262
00:16:32.730 --> 00:16:37.270
Ý tôi là bạn có các tế bào có thể biến thành nhãn cầu hoặc răng.

263
00:16:37.270 --> 00:16:42.440
Bây giờ, nếu các tế bào có thể làm điều đó, chúng chắc chắn có thể thực hiện sự lan truyền ngược và có

264
00:16:42.440 --> 00:16:45.860
lẽ là áp lực chọn lọc khổng lồ này đối với nó.

265
00:16:45.860 --> 00:16:50.490
Vì vậy, tôi nghĩ ý tưởng của nhà khoa học thần kinh rằng nó trông không hợp lý chỉ là ngớ ngẩn.

266
00:16:50.490 --> 00:16:52.890
Có thể có một số thực hiện tinh tế của nó.

267
00:16:52.890 --> 00:16:56.000
Và tôi nghĩ bộ não có lẽ có thứ gì đó có thể không chính xác

268
00:16:56.000 --> 00:16:58.620
là sự lan truyền ngược, nhưng nó khá gần với nó.

269
00:16:58.620 --> 00:17:02.566
Và trong những năm qua, tôi đã đưa ra một số ý tưởng về cách điều này có thể hoạt động.

270
00:17:02.566 --> 00:17:06.994
Vì vậy, vào năm 1987, làm việc với Jay McClelland,

271
00:17:06.994 --> 00:17:11.202
tôi đã nghĩ ra thuật toán tuần hoàn, trong đó

272
00:17:11.202 --> 00:17:16.090
ý tưởng là bạn gửi thông tin quanh một vòng lặp.

273
00:17:17.470 --> 00:17:18.686
Và bạn cố gắng làm cho mọi

274
00:17:18.686 --> 00:17:22.206
thứ không thay đổi khi thông tin đi quanh vòng lặp này.

275
00:17:22.206 --> 00:17:26.490
Vì vậy, phiên bản đơn giản nhất sẽ là bạn có các đơn vị đầu vào và đơn vị ẩn, và

276
00:17:26.490 --> 00:17:31.046
bạn gửi thông tin từ đầu vào đến ẩn và sau đó trở lại đầu vào, và

277
00:17:31.046 --> 00:17:34.388
sau đó quay lại ẩn và sau đó quay lại đầu vào, v.v.

278
00:17:34.388 --> 00:17:38.001
Và những gì bạn muốn, bạn muốn đào tạo một bộ mã hóa tự động,

279
00:17:38.001 --> 00:17:42.300
nhưng bạn muốn đào tạo nó mà không cần phải truyền ngược.

280
00:17:42.300 --> 00:17:47.250
Vì vậy, bạn chỉ cần đào tạo nó để cố gắng loại bỏ tất cả các biến thể trong các hoạt động.

281
00:17:47.250 --> 00:17:51.922
Vì vậy, ý tưởng là quy tắc học tập cho

282
00:17:51.922 --> 00:17:57.930
khớp thần kinh là thay đổi tỷ lệ trọng số đối với đầu vào trước synap và

283
00:17:57.930 --> 00:18:01.780
tỷ lệ thuận với tốc độ thay đổi ở đầu vào sau synap.

284
00:18:01.780 --> 00:18:04.060
Nhưng trong tuần hoàn, bạn đang cố gắng tạo đầu vào sau synap,

285
00:18:04.060 --> 00:18:08.330
bạn đang cố gắng làm cho cái cũ tốt và cái mới trở nên xấu, vì vậy

286
00:18:08.330 --> 00:18:09.620
bạn đang thay đổi theo hướng đó.

287
00:18:11.010 --> 00:18:14.472
Chúng tôi đã phát minh ra thuật toán này trước khi các nhà khoa học thần kinh đưa ra tính dẻo phụ thuộc vào thời gian

288
00:18:14.472 --> 00:18:16.521
tăng đột biến.

289
00:18:16.521 --> 00:18:20.700
Tính dẻo phụ thuộc vào thời gian tăng đột biến thực sự là cùng một thuật toán

290
00:18:20.700 --> 00:18:26.220
nhưng ngược lại, trong đó điều mới là tốt và điều cũ là xấu trong quy tắc học tập.

291
00:18:26.220 --> 00:18:30.010
Vì vậy, bạn đang thay đổi tỷ lệ trọng số thành hoạt động triển vọng đặt trước

292
00:18:30.010 --> 00:18:35.690
nhân lần hoạt động triển vọng người mới trừ đi hoạt động cũ.

293
00:18:37.060 --> 00:18:42.020
Sau đó, tôi nhận ra vào năm 2007, rằng nếu bạn lấy một chồng

294
00:18:42.020 --> 00:18:47.830
máy Boltzmann bị hạn chế và bạn đào tạo nó.

295
00:18:47.830 --> 00:18:52.620
Sau khi nó được đào tạo, sau đó bạn đã có chính xác các điều kiện thích hợp để triển

296
00:18:52.620 --> 00:18:56.450
khai nhân giống ngược bằng cách chỉ cố gắng tái tạo.

297
00:18:56.450 --> 00:19:01.124
Nếu bạn nhìn vào kỷ nguyên tái thiết, kỷ nguyên tái thiết đó

298
00:19:01.124 --> 00:19:05.728
thực sự sẽ cho bạn biết dẫn xuất của hiệu suất phân biệt đối xử.

299
00:19:05.728 --> 00:19:12.079
Và tại hội thảo học sâu đầu tiên vào năm 2007, tôi đã nói chuyện về điều đó.

300
00:19:12.079 --> 00:19:16.454
Điều đó gần như hoàn toàn bị bỏ qua.

301
00:19:16.454 --> 00:19:19.799
Sau đó, Joshua Benjo, đã tiếp nhận ý tưởng và điều

302
00:19:19.799 --> 00:19:24.340
đó thực sự đã thực hiện khá nhiều công việc hơn về điều đó.

303
00:19:24.340 --> 00:19:26.490
Và bản thân tôi đã làm nhiều việc hơn về nó.

304
00:19:26.490 --> 00:19:33.280
Và tôi nghĩ rằng nếu bạn có một đống bộ mã hóa tự động, thì bạn có thể

305
00:19:33.280 --> 00:19:38.440
lấy các dẫn xuất bằng cách gửi hoạt động ngược lại và xác định vị trí các công cụ tái tạo,

306
00:19:38.440 --> 00:19:42.520
là một ý tưởng thực sự thú vị và có thể là cách bộ não thực hiện điều đó.

307
00:19:42.520 --> 00:19:47.520
Một chủ đề khác mà tôi biết bạn theo dõi và tôi nghe nói bạn vẫn đang nghiên cứu

308
00:19:47.520 --> 00:19:51.930
là làm thế nào để đối phó với nhiều kỹ năng thời gian trong học sâu?

309
00:19:51.930 --> 00:19:54.468
Vì vậy, bạn có thể chia sẻ suy nghĩ của bạn về điều đó không?

310
00:19:54.468 --> 00:19:58.910
Vâng, vì vậy thực sự, điều đó quay trở lại những năm đầu tiên của tôi là sinh viên tốt nghiệp. Bài

311
00:19:58.910 --> 00:20:04.040
nói chuyện đầu tiên tôi từng đưa ra là về việc sử dụng cái mà tôi gọi là trọng lượng nhanh.

312
00:20:04.040 --> 00:20:07.560
Vì vậy, trọng lượng thích nghi nhanh, nhưng phân rã nhanh chóng.

313
00:20:07.560 --> 00:20:08.832
Và do đó có thể giữ trí nhớ ngắn hạn.

314
00:20:08.832 --> 00:20:13.496
Và tôi đã chỉ ra trong một hệ thống rất đơn giản vào năm 1973 rằng bạn có thể thực hiện đệ

315
00:20:13.496 --> 00:20:16.590
quy thực sự với các trọng số đó.

316
00:20:16.590 --> 00:20:23.010
Và ý tôi là đệ quy thực sự là các tế bào thần kinh được sử dụng để biểu diễn

317
00:20:23.010 --> 00:20:28.470
mọi thứ được sử dụng lại để biểu diễn các thứ trong lõi đệ quy.

318
00:20:30.210 --> 00:20:31.750
Và các trọng số được sử dụng cho

319
00:20:31.750 --> 00:20:34.388
kiến thức thực sự được sử dụng lại trong lõi đệ quy.

320
00:20:34.388 --> 00:20:39.170
Và điều đó dẫn đến câu hỏi khi bạn bật ra lõi đệ quy của

321
00:20:39.170 --> 00:20:41.600
mình, làm thế nào để bạn nhớ những gì bạn đang làm?

322
00:20:41.600 --> 00:20:42.970
Ký ức đó ở đâu?

323
00:20:42.970 --> 00:20:45.015
bởi vì bạn đã sử dụng các tế bào thần kinh cho lõi đệ quy.

324
00:20:46.080 --> 00:20:49.240
Và câu trả lời là bạn có thể đặt bộ nhớ đó vào trọng lượng nhanh, và

325
00:20:49.240 --> 00:20:53.940
bạn có thể phục hồi các tế bào thần kinh hoạt động từ những trọng lượng nhanh đó.

326
00:20:53.940 --> 00:20:56.151
Và gần đây làm việc với Jimmy Ba,

327
00:20:56.151 --> 00:21:00.141
chúng tôi thực sự có một bài báo trong đó bằng cách sử dụng trọng số nhanh cho đệ quy như thế.

328
00:21:00.141 --> 00:21:00.898
Tôi hiểu rồi.

329
00:21:00.898 --> 00:21:04.145
Vì vậy, đó là một khoảng cách khá lớn.

330
00:21:04.145 --> 00:21:08.746
Mô hình đầu tiên không được công bố vào năm 1973 và

331
00:21:08.746 --> 00:21:14.966
sau đó mô hình của Jimmy Ba là vào năm 2015, tôi nghĩ, hoặc năm 2016.

332
00:21:14.966 --> 00:21:16.469
Vì vậy, đó là khoảng 40 năm sau.

333
00:21:16.469 --> 00:21:22.840
Và, tôi đoán, một ý tưởng khác của Khá vài năm nay,

334
00:21:22.840 --> 00:21:29.350
hơn năm năm, tôi nghĩ là viên nang, bạn đang ở đâu với điều đó?

335
00:21:29.350 --> 00:21:34.150
Được rồi, vì vậy tôi đã trở lại trạng thái mà tôi đã quen.

336
00:21:34.150 --> 00:21:39.320
Đó là ý tưởng mà tôi thực sự tin tưởng và không ai khác tin vào nó.

337
00:21:39.320 --> 00:21:42.120
Và tôi gửi giấy tờ về nó và họ sẽ bị từ chối.

338
00:21:42.120 --> 00:21:45.938
Nhưng tôi thực sự tin vào ý tưởng này và tôi sẽ tiếp tục thúc đẩy nó.

339
00:21:45.938 --> 00:21:53.880
Vì vậy, nó phụ thuộc vào, có một vài ý tưởng chính.

340
00:21:53.880 --> 00:22:00.000
Một là về cách bạn đại diện cho các thực thể đa chiều, và bạn

341
00:22:00.000 --> 00:22:05.070
có thể đại diện cho các thực thể đa chiều chỉ bằng một số hoạt động cửa sau nhỏ.

342
00:22:05.070 --> 00:22:07.630
Miễn là bạn biết có ai trong số họ.

343
00:22:07.630 --> 00:22:12.150
Vì vậy, ý tưởng nằm ở mỗi vùng của hình ảnh, bạn sẽ cho rằng có nhiều nhất,

344
00:22:12.150 --> 00:22:14.000
một trong những loại tính năng cụ thể.

345
00:22:15.200 --> 00:22:18.020
Và sau đó bạn sẽ sử dụng một loạt các tế bào thần kinh và các

346
00:22:18.020 --> 00:22:23.190
hoạt động của chúng sẽ đại diện cho các khía cạnh khác nhau của đặc điểm đó,

347
00:22:24.230 --> 00:22:27.270
như trong khu vực đó chính xác tọa độ x và y của nó là gì?

348
00:22:27.270 --> 00:22:28.780
Nó ở định hướng nào? Nó

349
00:22:28.780 --> 00:22:29.930
di chuyển nhanh như thế nào?

350
00:22:29.930 --> 00:22:30.630
Nó có màu gì?

351
00:22:30.630 --> 00:22:31.270
Nó sáng đến mức nào?

352
00:22:31.270 --> 00:22:32.590
Và những thứ như thế.

353
00:22:32.590 --> 00:22:36.350
Vì vậy, bạn có thể sử dụng cả một loạt các tế bào thần kinh để đại diện cho các kích thước khác nhau

354
00:22:36.350 --> 00:22:37.710
của cùng một thứ.

355
00:22:37.710 --> 00:22:39.410
Miễn là chỉ có một trong số họ.

356
00:22:40.490 --> 00:22:46.110
Đó là một cách thực hiện biểu diễn rất khác

357
00:22:46.110 --> 00:22:48.155
so với những gì chúng ta thường sử dụng trong mạng nơ-ron.

358
00:22:48.155 --> 00:22:49.820
Thông thường trong mạng lưới thần kinh, chúng ta chỉ có một lớp lớn lớn,

359
00:22:49.820 --> 00:22:52.080
và tất cả các đơn vị sẽ hoạt động và làm bất cứ điều gì chúng làm.

360
00:22:52.080 --> 00:22:55.770
Nhưng bạn không nghĩ đến việc nhóm chúng thành các nhóm nhỏ đại diện cho các

361
00:22:55.770 --> 00:22:57.310
tọa độ khác nhau của cùng một thứ.

362
00:22:58.660 --> 00:23:02.080
Vì vậy, tôi nghĩ chúng ta nên đánh bại cấu trúc bổ sung này.

363
00:23:02.080 --> 00:23:05.020
Và sau đó là ý tưởng khác đi kèm với điều đó.

364
00:23:05.020 --> 00:23:07.410
Vì vậy, điều này có nghĩa là trong trut 367 00:23:09,280 --&gt; 00:23:11,270 Vâng. Đến các tập con khác nhau.

365
00:23:11.270 --> 00:23:13.900
Vâng. Để đại diện, đúng chứ không phải -

366
00:23:13.900 --> 00:23:15.600
tôi gọi mỗi tập hợp con đó là một viên nang.

367
00:23:15.600 --> 00:23:16.180
Tôi hiểu rồi.

368
00:23:16.180 --> 00:23:21.078
Và ý tưởng là một viên nang có thể đại diện cho một ví dụ của một tính năng, nhưng

369
00:23:21.078 --> 00:23:21.794
chỉ có một.

370
00:23:21.794 --> 00:23:27.130
Và nó đại diện cho tất cả các thuộc tính khác nhau của tính năng đó.

371
00:23:27.130 --> 00:23:29.880
Đó là một tính năng có rất nhiều đặc tính trái ngược với

372
00:23:29.880 --> 00:23:34.530
một tế bào thần kinh bình thường và mạng nơ-ron bình thường, chỉ có một thang tính chất.

373
00:23:34.530 --> 00:23:36.240
Vâng, tôi thấy đúng.

374
00:23:36.240 --> 00:23:41.423
Và sau đó, những gì bạn có thể làm nếu bạn có điều đó, là bạn có thể làm điều mà mạng

375
00:23:41.423 --> 00:23:48.980
nơ-ron bình thường rất tệ, đó là bạn có thể làm những gì tôi gọi là thói quen theo thỏa thuận.

376
00:23:48.980 --> 00:23:52.960
Vì vậy, giả sử bạn muốn thực hiện phân đoạn và

377
00:23:52.960 --> 00:23:56.660
bạn có thứ gì đó có thể là miệng và thứ khác có thể là mũi.

378
00:23:57.910 --> 00:24:02.179
Và bạn muốn biết liệu bạn có nên ghép chúng lại với nhau để tạo ra một điều không.

379
00:24:02.179 --> 00:24:03.879
Vì vậy, ý tưởng nên có

380
00:24:03.879 --> 00:24:06.040
một viên nang cho miệng có các thông số của miệng.

381
00:24:06.040 --> 00:24:10.582
Và bạn có một viên nang cho mũi có các thông số của mũi.

382
00:24:10.582 --> 00:24:13.797
Và sau đó để giải mã có nên ghép chúng lại với nhau hay

383
00:24:13.797 --> 00:24:18.670
không, bạn yêu cầu mỗi người trong số họ bỏ phiếu cho các thông số nên là gì cho một khuôn mặt.

384
00:24:19.930 --> 00:24:23.718
Bây giờ nếu miệng và mũi ở trong mối quan hệ không gian phù hợp,

385
00:24:23.718 --> 00:24:24.725
họ sẽ đồng ý.

386
00:24:24.725 --> 00:24:28.888
Vì vậy, khi bạn nhận được hai ảnh chụp ở một cấp độ bỏ phiếu cho cùng một tập hợp các tham số ở

387
00:24:28.888 --> 00:24:32.106
cấp độ tiếp theo, bạn có thể giả định chúng có thể đúng,

388
00:24:32.106 --> 00:24:35.350
bởi vì sự đồng ý trong không gian chiều cao rất khó xảy ra.

389
00:24:36.950 --> 00:24:42.109
Và đó là một cách thực hiện lọc rất khác

390
00:24:42.109 --> 00:24:46.130
so với những gì chúng ta thường sử dụng trong mạng nơ-ron.

391
00:24:46.130 --> 00:24:50.708
Vì vậy, tôi nghĩ rằng định tuyến theo thỏa thuận này sẽ rất quan trọng để làm cho

392
00:24:50.708 --> 00:24:56.700
các mạng thần kinh khái quát hóa tốt hơn nhiều từ dữ liệu hạn chế.

393
00:24:56.700 --> 00:24:59.797
Tôi nghĩ nó sẽ rất tốt trong việc nhận được những thay đổi về quan điểm,

394
00:24:59.797 --> 00:25:01.500
rất tốt trong việc phân đoạn.

395
00:25:01.500 --> 00:25:04.794
Và tôi hy vọng nó sẽ hiệu quả hơn nhiều về mặt thống kê so với những gì chúng ta

396
00:25:04.794 --> 00:25:06.147
hiện đang làm trong mạng lưới thần kinh.

397
00:25:06.147 --> 00:25:08.575
Nghĩa là, nếu bạn muốn đối phó với những thay đổi trong quan điểm,

398
00:25:08.575 --> 00:25:12.000
bạn chỉ cần cung cấp cho nó một loạt các thay đổi về quan điểm và đào tạo về tất cả chúng.

399
00:25:12.000 --> 00:25:16.460
Tôi hiểu, đúng vậy, vì vậy thay vì học FIFO, học có giám sát,

400
00:25:16.460 --> 00:25:19.120
bạn có thể học điều này theo một cách khác.

401
00:25:20.220 --> 00:25:24.120
Chà, tôi vẫn dự định làm điều đó với việc học có giám sát, nhưng

402
00:25:24.120 --> 00:25:27.720
cơ chế của các con đường phía trước rất khác nhau.

403
00:25:27.720 --> 00:25:32.010
Đó không phải là một con đường tiến về phía trước thuần túy theo nghĩa là có những đoạn lặp đi lặp lại nhỏ đang

404
00:25:32.010 --> 00:25:36.550
diễn ra, nơi bạn nghĩ rằng bạn đã tìm thấy một cái miệng và bạn nghĩ rằng bạn đã tìm thấy một cái mũi.

405
00:25:36.550 --> 00:25:39.127
Và sử dụng một chút lặp lại để quyết định

406
00:25:39.127 --> 00:25:42.530
liệu họ có thực sự nên đi cùng nhau để tạo ra một khuôn mặt hay không.

407
00:25:42.530 --> 00:25:46.352
Và bạn có thể làm đạo cụ trở lại từ lần lặp đó.

408
00:25:46.352 --> 00:25:50.286
Vì vậy, bạn có thể thử và làm điều đó một cách phân biệt một chút,

409
00:25:50.286 --> 00:25:54.417
và chúng tôi đang nghiên cứu điều đó ngay bây giờ tại nhóm của tôi ở Toronto.

410
00:25:54.417 --> 00:26:00.260
Vì vậy, bây giờ tôi có một nhóm Google nhỏ ở Toronto, một phần của nhóm Brain.

411
00:26:00.260 --> 00:26:02.127
Đó là những gì tôi hào hứng ngay bây giờ.

412
00:26:02.127 --> 00:26:02.891
Tôi hiểu rồi, tuyệt vời, vâng.

413
00:26:02.891 --> 00:26:05.366
Mong đợi bài báo đó khi nó xuất hiện.

414
00:26:05.366 --> 00:26:10.750
Vâng, nếu nó xuất hiện [cười].

415
00:26:10.750 --> 00:26:13.040
Bạn đã làm việc trong lĩnh vực học sâu trong nhiều thập kỷ.

416
00:26:13.040 --> 00:26:15.330
Tôi thực sự rất tò mò, suy nghĩ của bạn,

417
00:26:15.330 --> 00:26:18.760
hiểu biết của bạn về AI đã thay đổi như thế nào trong những năm qua?

418
00:26:20.380 --> 00:26:27.678
Vì vậy, tôi đoán rất nhiều lịch sử trí tuệ của tôi đã xoay quanh việc truyền bá ngược lại,

419
00:26:27.678 --> 00:26:33.531
và làm thế nào để sử dụng truyền bá ngược, làm thế nào để tận dụng sức mạnh của nó.

420
00:26:33.531 --> 00:26:36.966
Vì vậy, bắt đầu, vào giữa những năm 80, chúng tôi đã sử dụng nó để

421
00:26:36.966 --> 00:26:40.203
học tập phân biệt đối xử và nó hoạt động tốt.

422
00:26:40.203 --> 00:26:42.405
Sau đó, tôi quyết định, vào đầu những năm 90,

423
00:26:42.405 --> 00:26:46.749
rằng thực sự hầu hết việc học của con người sẽ là học tập không có giám sát.

424
00:26:46.749 --> 00:26:50.138
Và tôi quan tâm nhiều hơn đến việc học không giám sát, và

425
00:26:50.138 --> 00:26:54.300
đó là khi tôi làm việc trên những thứ như thuật toán Wegstein.

426
00:26:54.300 --> 00:26:58.306
Và ý kiến của bạn vào thời điểm đó cũng thực sự ảnh hưởng đến suy nghĩ của tôi.

427
00:26:58.306 --> 00:27:03.010
Vì vậy, khi tôi lãnh đạo Google Brain, dự án đầu tiên của chúng tôi đã dành rất nhiều

428
00:27:03.010 --> 00:27:07.900
công việc trong việc học tập không giám sát vì ảnh hưởng của bạn.

429
00:27:07.900 --> 00:27:09.740
Đúng vậy, và tôi có thể đã lừa bạn.

430
00:27:09.740 --> 00:27:11.470
Bởi vì về lâu dài,

431
00:27:11.470 --> 00:27:13.840
tôi nghĩ rằng việc học không có giám sát sẽ hoàn toàn quan trọng.

432
00:27:15.160 --> 00:27:19.376
Nhưng bạn phải đối mặt với thực tế.

433
00:27:19.376 --> 00:27:24.107
Và những gì đã hoạt động trong mười năm qua hoặc lâu hơn là học tập có giám sát.

434
00:27:24.107 --> 00:27:27.179
Đào tạo phân biệt đối xử, nơi bạn có nhãn hiệu hoặc

435
00:27:27.179 --> 00:27:31.810
bạn đang cố gắng dự đoán điều tiếp theo trong loạt bài, vì vậy nó đóng vai trò là nhãn hiệu.

436
00:27:31.810 --> 00:27:33.769
Và điều đó đã hoạt động cực kỳ tốt.

437
00:27:37.528 --> 00:27:42.266
Tôi vẫn tin rằng việc học tập không giám sát sẽ rất quan trọng, và mọi thứ sẽ

438
00:27:42.266 --> 00:27:47.145
hoạt động tốt hơn rất nhiều so với bây giờ khi chúng ta làm cho nó hoạt động bình thường, nhưng

439
00:27:47.145 --> 00:27:48.200
chúng ta vẫn chưa làm được.

440
00:27:49.990 --> 00:27:53.225
Vâng, tôi nghĩ rằng nhiều người cao cấp trong học sâu,

441
00:27:53.225 --> 00:27:56.074
bao gồm cả bản thân tôi, vẫn rất hào hứng với nó.

442
00:27:56.074 --> 00:28:01.513
Chỉ là chưa ai trong chúng ta thực sự có ý tưởng làm thế nào để làm điều đó.

443
00:28:01.513 --> 00:28:04.983
Có lẽ bạn có, tôi không cảm thấy như tôi cảm thấy như vậy.

444
00:28:04.983 --> 00:28:08.160
Mã thay đổi biến thể là nơi bạn sử dụng các thủ thuật tham số hóa lại. Đối với

445
00:28:08.160 --> 00:28:10.120
tôi dường như là một ý tưởng thực sự tốt.

446
00:28:10.120 --> 00:28:15.260
Và đối với tôi, lưới đối nghịch tạo cũng dường như là một ý tưởng thực sự hay.

447
00:28:15.260 --> 00:28:18.645
Tôi nghĩ rằng mạng đối nghịch tạo là một trong những

448
00:28:18.645 --> 00:28:23.430
ý tưởng lớn nhất trong học sâu thực sự mới mẻ.

449
00:28:23.430 --> 00:28:26.363
Tôi hy vọng mình có thể tạo ra những viên nang thành công như vậy, nhưng

450
00:28:26.363 --> 00:28:31.740
ngay bây giờ, mạng lưới đối nghịch tạo, tôi nghĩ, đã là một bước đột phá lớn.

451
00:28:31.740 --> 00:28:34.439
Điều gì đã xảy ra với các tính năng thưa thớt và chậm,

452
00:28:34.439 --> 00:28:38.806
đó là hai trong số các nguyên tắc khác để xây dựng các mô hình không được giám sát?

453
00:28:41.556 --> 00:28:47.788
Tôi chưa bao giờ thích sự thưa thớt như anh, anh bạn.

454
00:28:47.788 --> 00:28:52.672
Nhưng các tính năng chậm, tôi nghĩ, là một sai lầm.

455
00:28:52.672 --> 00:28:53.660
Bạn không nên nói chậm.

456
00:28:53.660 --> 00:28:57.880
Ý tưởng cơ bản là đúng, nhưng bạn không nên chọn các tính năng không thay đổi,

457
00:28:57.880 --> 00:29:00.660
bạn nên chọn các tính năng thay đổi theo những cách có thể dự đoán được.

458
00:29:01.680 --> 00:29:07.060
Vì vậy, đây là một loại nguyên tắc cơ bản về cách bạn mô hình hóa bất cứ thứ gì.

459
00:29:08.620 --> 00:29:13.391
Bạn thực hiện các phép đo của mình và bạn đang áp dụng các phép

460
00:29:13.391 --> 00:29:17.612
biến đổi phi tuyến cho các phép đo của mình cho đến khi bạn đến

461
00:29:17.612 --> 00:29:22.672
một biểu diễn dưới dạng vectơ trạng thái trong đó hành động là tuyến tính.

462
00:29:22.672 --> 00:29:26.103
Vì vậy, bạn không chỉ giả vờ nó tuyến tính như bạn làm với các bộ lọc thông thường.

463
00:29:26.103 --> 00:29:29.625
Nhưng bạn thực sự tìm thấy một sự chuyển đổi từ các biến quan sát sang

464
00:29:29.625 --> 00:29:32.616
các biến cơ bản trong đó các phép toán tuyến tính,

465
00:29:32.616 --> 00:29:37.480
như hệ số nhân ma trận trên các biến cơ bản, sẽ thực hiện công việc.

466
00:29:37.480 --> 00:29:39.700
Ví dụ, nếu bạn muốn thay đổi quan điểm.

467
00:29:39.700 --> 00:29:42.890
Nếu bạn muốn tạo ra hình ảnh từ một góc nhìn khác,

468
00:29:42.890 --> 00:29:46.900
những gì bạn nên làm là đi từ pixel đến tọa độ.

469
00:29:47.950 --> 00:29:50.686
Và một khi bạn đã đến biểu diễn tọa độ,

470
00:29:50.686 --> 00:29:54.120
đó là một thứ mà tôi hy vọng các ảnh chụp sẽ tìm thấy.

471
00:29:54.120 --> 00:29:57.350
Sau đó, bạn có thể thực hiện hệ số nhân ma trận để thay đổi góc nhìn và

472
00:29:57.350 --> 00:29:59.210
sau đó bạn có thể ánh xạ nó trở lại các pixel.

473
00:29:59.210 --> 00:29:59.893
Đúng vậy, đó là lý do tại sao bạn làm tất cả những điều đó.

474
00:29:59.893 --> 00:30:02.170
Tôi nghĩ đó là một nguyên tắc rất, rất chung chung.

475
00:30:02.170 --> 00:30:04.773
Đó là lý do tại sao bạn đã làm tất cả công việc đó về tổng hợp khuôn mặt, phải không?

476
00:30:04.773 --> 00:30:09.355
Nơi bạn lấy một khuôn mặt và nén nó thành vectơ có chiều rất thấp, và vì vậy

477
00:30:09.355 --> 00:30:12.450
bạn có thể chơi với nó và lấy lại những khuôn mặt khác.

478
00:30:12.450 --> 00:30:15.950
Tôi đã có một sinh viên làm việc trên đó, bản thân tôi đã không làm nhiều việc về điều đó.

479
00:30:17.100 --> 00:30:19.180
Bây giờ tôi chắc chắn rằng bạn vẫn luôn được hỏi,

480
00:30:19.180 --> 00:30:23.920
nếu ai đó muốn học sâu, họ nên làm gì?

481
00:30:23.920 --> 00:30:25.040
Vậy bạn sẽ có lời khuyên gì?

482
00:30:25.040 --> 00:30:28.938
Tôi chắc chắn rằng bạn đã đưa ra rất nhiều lời khuyên cho mọi người trong cài đặt một đối một, nhưng dành cho

483
00:30:28.938 --> 00:30:31.550
khán giả toàn cầu của những người xem video này.

484
00:30:31.550 --> 00:30:35.999
Bạn sẽ có lời khuyên nào cho họ để học sâu?

485
00:30:35.999 --> 00:30:42.171
Được rồi, vì vậy lời khuyên của tôi là đọc tài liệu, nhưng đừng đọc quá nhiều.

486
00:30:42.171 --> 00:30:48.030
Vì vậy, đây là lời khuyên tôi nhận được từ cố vấn của mình, điều này rất khác với những gì hầu hết mọi người nói.

487
00:30:48.030 --> 00:30:52.474
Hầu hết mọi người nói rằng bạn nên dành vài năm để đọc tài liệu và

488
00:30:52.474 --> 00:30:55.421
sau đó bạn nên bắt đầu làm việc theo ý tưởng của riêng mình.

489
00:30:55.421 --> 00:31:00.295
Và điều đó có thể đúng với một số nhà nghiên cứu, nhưng đối với các nhà nghiên cứu sáng tạo, tôi nghĩ những

490
00:31:00.295 --> 00:31:03.803
gì bạn muốn làm là đọc một chút tài liệu.

491
00:31:03.803 --> 00:31:07.792
Và để ý điều gì đó mà bạn nghĩ rằng mọi người đang làm sai,

492
00:31:07.792 --> 00:31:10.340
tôi ngược lại theo nghĩa đó.

493
00:31:10.340 --> 00:31:13.568
Bạn nhìn vào nó và nó chỉ cảm thấy không đúng.

494
00:31:13.568 --> 00:31:15.660
Và sau đó tìm ra cách làm đúng.

495
00:31:16.890 --> 00:31:22.476
Và sau đó khi mọi người nói với bạn, điều đó không tốt, hãy cứ tiếp tục làm điều đó.

496
00:31:22.476 --> 00:31:26.339
Và tôi có một nguyên tắc rất tốt để giúp mọi người duy trì nó,

497
00:31:26.339 --> 00:31:29.996
đó là trực giác của bạn tốt hoặc không.

498
00:31:29.996 --> 00:31:32.030
Nếu trực giác của bạn tốt, bạn nên làm theo chúng và

499
00:31:32.030 --> 00:31:34.060
cuối cùng bạn sẽ thành công.

500
00:31:34.060 --> 00:31:36.478
Nếu trực giác của bạn không tốt, điều đó không quan trọng bạn làm.

501
00:31:36.478 --> 00:31:40.329
Tôi thấy [cười].

502
00:31:40.329 --> 00:31:43.420
Lời khuyên đầy cảm hứng, cũng có thể làm theo nó.

503
00:31:43.420 --> 00:31:45.410
Bạn cũng có thể tin tưởng vào trực giác của mình.

504
00:31:45.410 --> 00:31:47.847
Không có lý do gì không tin tưởng họ.

505
00:31:47.847 --> 00:31:49.420
Tôi hiểu rồi.

506
00:31:49.420 --> 00:31:55.193
Tôi thường khuyên mọi người không chỉ đọc, mà còn sao chép các bài báo đã xuất bản.

507
00:31:55.193 --> 00:31:58.161
Và có lẽ điều đó đặt ra một giới hạn tự nhiên về số lượng bạn có thể làm,

508
00:31:58.161 --> 00:32:00.800
bởi vì việc sao chép kết quả khá tốn thời gian.

509
00:32:01.910 --> 00:32:05.312
Vâng, đúng là khi bạn đang cố gắng sao chép một bài xuất bản,

510
00:32:05.312 --> 00:32:08.100
bạn sẽ khám phá ra tất cả các thủ thuật nhỏ cần thiết để làm cho nó hoạt động.

511
00:32:08.100 --> 00:32:11.938
Một lời khuyên khác của tôi là, đừng bao giờ ngừng lập trình.

512
00:32:11.938 --> 00:32:15.577
Bởi vì nếu bạn cho một học sinh điều gì đó để làm, nếu họ là một học sinh tồi,

513
00:32:15.577 --> 00:32:18.550
họ sẽ quay lại và nói rằng, nó không hiệu quả.

514
00:32:18.550 --> 00:32:22.030
Và lý do nó không hiệu quả sẽ là một quyết định nhỏ mà họ đưa ra,

515
00:32:22.030 --> 00:32:25.100
mà họ không nhận ra là rất quan trọng.

516
00:32:25.100 --> 00:32:28.850
Và nếu bạn đưa nó cho một sinh viên giỏi, chẳng hạn như.

517
00:32:28.850 --> 00:32:31.120
Bạn có thể cho anh ấy bất cứ thứ gì và anh ấy sẽ quay lại và nói, nó đã hoạt động.

518
00:32:32.670 --> 00:32:36.420
Tôi nhớ đã làm điều này một lần, và tôi nói, nhưng chờ một chút.

519
00:32:36.420 --> 00:32:37.330
Kể từ lần cuối chúng tôi nói chuyện,

520
00:32:37.330 --> 00:32:40.380
tôi nhận ra nó không thể hoạt động vì lý do sau đây.

521
00:32:40.380 --> 00:32:43.586
Và nói, vâng, tôi nhận ra điều đó ngay lập tức, vì vậy tôi cho rằng bạn không có ý đó.

522
00:32:43.586 --> 00:32:47.627
[CƯỜI] Tôi thấy, vâng, điều đó thật tuyệt, vâng.

523
00:32:47.627 --> 00:32:51.575
Hãy xem, có lời khuyên nào khác cho

524
00:32:51.575 --> 00:32:57.782
những người muốn đột nhập vào AI và deep learning không?

525
00:32:57.782 --> 00:33:02.000
Tôi nghĩ rằng về cơ bản, hãy đọc đủ để bạn bắt đầu phát triển trực giác.

526
00:33:02.000 --> 00:33:05.811
Và sau đó, hãy tin vào trực giác của bạn và làm theo nó,

527
00:33:05.811 --> 00:33:10.783
đừng quá lo lắng nếu mọi người khác nói rằng đó là vô nghĩa.

528
00:33:10.783 --> 00:33:14.352
Và tôi đoán không có cách nào để biết người khác đúng hay

529
00:33:14.352 --> 00:33:19.950
sai khi họ nói điều đó là vô nghĩa, nhưng bạn chỉ cần làm điều đó, và sau đó tìm hiểu.

530
00:33:19.950 --> 00:33:24.350
Đúng vậy, nhưng có một điều, đó là, nếu bạn nghĩ đó là một ý tưởng thực sự tốt,

531
00:33:24.350 --> 00:33:27.201
và những người khác nói với bạn rằng đó là điều hoàn toàn vô nghĩa,

532
00:33:27.201 --> 00:33:29.761
thì bạn biết bạn thực sự đang tìm kiếm điều gì đó.

533
00:33:29.761 --> 00:33:33.960
Vì vậy, một ví dụ về điều đó là khi và tôi lần đầu tiên đưa ra các phương pháp biến thể.

534
00:33:35.420 --> 00:33:40.690
Tôi đã gửi thư giải thích điều đó cho một cựu sinh viên của tôi tên là Peter Brown,

535
00:33:40.690 --> 00:33:42.560
người biết rất nhiều về nó.

536
00:33:43.570 --> 00:33:46.967
Và anh ấy đã cho những người làm việc với anh ấy,

537
00:33:46.967 --> 00:33:51.253
gọi là anh em, họ là cặp song sinh, tôi nghĩ.

538
00:33:51.253 --> 00:33:55.914
Và sau đó anh ấy nói với tôi những gì họ nói, và họ nói,

539
00:33:55.914 --> 00:34:00.277
hoặc anh ấy say rượu, hoặc anh ấy chỉ ngu ngốc, vì vậy

540
00:34:00.277 --> 00:34:04.260
họ thực sự, thực sự nghĩ rằng đó là vô nghĩa.

541
00:34:04.260 --> 00:34:06.460
Bây giờ, nó có thể một phần là cách tôi giải thích nó,

542
00:34:06.460 --> 00:34:08.043
bởi vì tôi đã giải thích nó bằng các thuật ngữ trực quan.

543
00:34:09.150 --> 00:34:13.100
Nhưng khi bạn có những gì bạn nghĩ là một ý tưởng tốt và

544
00:34:13.100 --> 00:34:16.810
người khác nghĩ là hoàn toàn rác rưởi, đó là dấu hiệu của một ý tưởng thực sự tốt.

545
00:34:18.026 --> 00:34:21.555
Tôi thấy, và các chủ đề nghiên cứu, sinh viên

546
00:34:21.555 --> 00:34:26.183
mới tốt nghiệp nên làm việc trên các viên nang và

547
00:34:26.183 --> 00:34:30.707
có thể học tập không có giám sát, bất kỳ thứ gì khác không?

548
00:34:30.707 --> 00:34:34.078
Một lời khuyên tốt cho sinh viên mới tốt nghiệp là, hãy

549
00:34:34.078 --> 00:34:38.344
xem liệu bạn có thể tìm thấy một cố vấn có niềm tin tương tự như bạn không.

550
00:34:38.344 --> 00:34:42.637
Bởi vì nếu bạn làm việc với những thứ mà cố vấn của bạn cảm thấy sâu sắc,

551
00:34:42.637 --> 00:34:47.170
bạn sẽ nhận được rất nhiều lời khuyên và thời gian tốt từ cố vấn của bạn.

552
00:34:47.170 --> 00:34:50.590
Nếu bạn làm việc với những thứ mà cố vấn của bạn không quan tâm,

553
00:34:50.590 --> 00:34:55.262
tất cả những gì bạn sẽ nhận được là bạn nhận được một số lời khuyên, nhưng nó sẽ không hữu ích lắm.

554
00:34:55.262 --> 00:34:58.386
Tôi hiểu, và cuối cùng là lời khuyên dành cho người học,

555
00:34:58.386 --> 00:35:02.440
bạn cảm thấy thế nào về những người tham gia chương trình tiến sĩ?

556
00:35:02.440 --> 00:35:09.687
So với tham gia một công ty hàng đầu, hoặc một nhóm nghiên cứu hàng đầu?

557
00:35:09.687 --> 00:35:13.890
Vâng, nó rất phức tạp, tôi nghĩ ngay bây giờ, những gì đang xảy ra là,

558
00:35:13.890 --> 00:35:18.727
không có đủ các học giả được đào tạo về đào tạo sâu để giáo dục tất cả những người

559
00:35:18.727 --> 00:35:21.125
mà chúng ta cần được đào tạo trong các trường đại học.

560
00:35:21.125 --> 00:35:25.011
Không có băng thông giảng viên ở đó, nhưng

561
00:35:25.011 --> 00:35:27.780
tôi nghĩ đó sẽ là tạm thời.

562
00:35:27.780 --> 00:35:32.410
Tôi nghĩ những gì đã xảy ra là, hầu hết các bộ phận đều rất chậm

563
00:35:32.410 --> 00:35:34.890
hiểu loại cuộc cách mạng đang diễn ra.

564
00:35:34.890 --> 00:35:38.720
Tôi đồng ý với bạn, rằng đây không phải là một cuộc cách mạng công nghiệp thứ hai, nhưng

565
00:35:38.720 --> 00:35:41.000
nó là một cái gì đó ở quy mô gần như vậy.

566
00:35:41.000 --> 00:35:43.691
Và có một sự thay đổi lớn đang diễn ra, về

567
00:35:43.691 --> 00:35:47.980
cơ bản là vì mối quan hệ của chúng ta với máy tính đã thay đổi.

568
00:35:47.980 --> 00:35:53.920
Thay vì lập trình chúng, bây giờ chúng tôi chỉ cho họ thấy và họ tìm ra điều đó.

569
00:35:53.920 --> 00:35:56.570
Đó là một cách sử dụng máy tính hoàn toàn khác, và các

570
00:35:56.570 --> 00:36:01.210
khoa khoa học máy tính được xây dựng xung quanh ý tưởng lập trình máy tính.

571
00:36:01.210 --> 00:36:03.480
Và họ không hiểu điều đó, điều

572
00:36:05.000 --> 00:36:09.330
này cho thấy máy tính sẽ lớn như máy tính lập trình.

573
00:36:09.330 --> 00:36:13.940
Ngoại trừ họ không hiểu rằng một nửa số người trong bộ phận nên là những

574
00:36:13.940 --> 00:36:16.510
người khiến máy tính làm mọi việc bằng cách cho họ thấy.

575
00:36:16.510 --> 00:36:22.183
Vì vậy, bộ phận của tôi từ chối thừa nhận rằng nó nên có

576
00:36:22.183 --> 00:36:24.790
rất nhiều người làm điều này.

577
00:36:24.790 --> 00:36:28.730
Họ nghĩ rằng họ có một cặp, có thể thêm một vài, nhưng không quá nhiều.

578
00:36:31.260 --> 00:36:32.452
Và trong tình huống đó,

579
00:36:32.452 --> 00:36:36.510
bạn phải nhắc nhở các công ty lớn thực hiện khá nhiều khóa đào tạo.

580
00:36:36.510 --> 00:36:40.335
Vì vậy, Google hiện đang đào tạo mọi người, chúng tôi gọi là nơi cư trú của não,

581
00:36:40.335 --> 00:36:43.792
tôi nghi ngờ các trường đại học cuối cùng sẽ bắt kịp.

582
00:36:43.792 --> 00:36:48.360
Tôi thấy, đúng vậy, trên thực tế, có lẽ rất nhiều sinh viên đã tìm ra điều này.

583
00:36:48.360 --> 00:36:53.131
Rất nhiều chương trình hàng đầu của 50 chương trình, hơn một nửa số ứng viên thực

584
00:36:53.131 --> 00:36:57.079
sự muốn làm việc để trình diễn, thay vì lập trình.

585
00:36:57.079 --> 00:37:00.720
Vâng, thật tuyệt, vâng, trên thực tế, để ghi công ở nơi cần thiết,

586
00:37:00.720 --> 00:37:04.930
trong khi AI học sâu đang tạo ra một chuyên môn học sâu.

587
00:37:04.930 --> 00:37:09.239
Theo như tôi biết, MOOC học sâu đầu tiên của họ thực sự là của bạn

588
00:37:09.239 --> 00:37:11.752
được dạy trên Coursera, vào năm 2012.

589
00:37:12.828 --> 00:37:14.430
Và hơi kỳ lạ,

590
00:37:14.430 --> 00:37:18.900
đó là khi bạn lần đầu tiên xuất bản thuật toán RMS, đây cũng là một thuật toán thô sơ.

591
00:37:20.240 --> 00:37:25.910
Đúng, vâng, như bạn biết, đó là vì bạn mời tôi làm MOOC.

592
00:37:25.910 --> 00:37:30.239
Và sau đó khi tôi rất nghi ngờ về việc làm, bạn tiếp tục thúc đẩy tôi làm điều đó, vì vậy

593
00:37:30.239 --> 00:37:34.340
tôi đã làm rất tốt, mặc dù đó là rất nhiều công việc.

594
00:37:34.340 --> 00:37:37.409
Vâng, và cảm ơn bạn đã làm điều đó, tôi nhớ bạn phàn nàn với tôi,

595
00:37:37.409 --> 00:37:38.351
công việc đó là bao nhiêu.

596
00:37:38.351 --> 00:37:42.413
Và bạn ở ngoài khuya, nhưng tôi nghĩ rất nhiều người học đã được

597
00:37:42.413 --> 00:37:47.330
hưởng lợi cho MOOC đầu tiên của bạn, vì vậy tôi rất biết ơn bạn vì điều đó.

598
00:37:47.330 --> 00:37:49.260
Điều đó thật tốt, vâng Vâng, trong những năm qua,

599
00:37:49.260 --> 00:37:53.290
tôi đã thấy bạn bị lôi kéo vào các cuộc tranh luận về các mô hình cho AI và

600
00:37:53.290 --> 00:37:57.030
liệu có sự thay đổi mô hình cho AI hay không. Bạn

601
00:37:57.030 --> 00:37:59.984
là gì, bạn có thể chia sẻ suy nghĩ của bạn về điều đó không?

602
00:37:59.984 --> 00:38:05.157
Vâng, may mắn thay, vì vậy tôi nghĩ rằng trong những ngày đầu, vào những năm 50, những

603
00:38:05.157 --> 00:38:10.335
người như von Neumann và Turing không tin vào AI tượng trưng,

604
00:38:10.335 --> 00:38:14.220
họ được truyền cảm hứng nhiều hơn từ bộ não.

605
00:38:14.220 --> 00:38:20.127
Thật không may, cả hai đều chết quá trẻ, và giọng nói của họ không được nghe thấy.

606
00:38:20.127 --> 00:38:21.806
Và trong những ngày đầu của AI, mọi

607
00:38:21.806 --> 00:38:26.259
người hoàn toàn tin rằng những biểu hiện bạn cần cho

608
00:38:26.259 --> 00:38:30.500
trí thông minh là những biểu hiện tượng trưng của một số loại.

609
00:38:30.500 --> 00:38:35.509
Loại logic được dọn dẹp, nơi bạn có thể làm những việc không đơn điệu, và không hoàn toàn

610
00:38:35.509 --> 00:38:41.143
logic, mà là một cái gì đó giống như logic, và bản chất của trí thông minh là lý luận.

611
00:38:41.143 --> 00:38:45.662
Những gì đã xảy ra bây giờ là, có một quan điểm hoàn toàn khác,

612
00:38:45.662 --> 00:38:50.984
đó là suy nghĩ là gì, chỉ là một vectơ lớn của hoạt động thần kinh,

613
00:38:50.984 --> 00:38:55.200
tương phản với ý nghĩ là một biểu hiện tượng trưng.

614
00:38:55.200 --> 00:38:59.087
Và tôi nghĩ những người nghĩ rằng suy nghĩ là biểu hiện tượng trưng đã

615
00:38:59.087 --> 00:39:00.140
phạm một sai lầm lớn.

616
00:39:01.210 --> 00:39:07.030
Những gì đi vào là một chuỗi từ, và những gì xuất hiện là một chuỗi từ.

617
00:39:08.140 --> 00:39:12.580
Và vì điều đó, chuỗi từ là cách hiển nhiên để thể hiện mọi thứ.

618
00:39:12.580 --> 00:39:15.710
Vì vậy, họ nghĩ những gì phải ở giữa là một chuỗi từ, hoặc một

619
00:39:15.710 --> 00:39:18.360
cái gì đó giống như một chuỗi từ.

620
00:39:18.360 --> 00:39:21.310
Và tôi nghĩ những gì ở giữa không giống như một chuỗi từ.

621
00:39:21.310 --> 00:39:26.060
Tôi nghĩ ý tưởng rằng suy nghĩ phải bằng một loại ngôn ngữ nào đó cũng ngớ ngẩn như

622
00:39:26.060 --> 00:39:30.980
ý tưởng rằng hiểu bố cục của một cảnh không gian

623
00:39:30.980 --> 00:39:34.280
phải bằng pixel, pixel xuất hiện.

624
00:39:34.280 --> 00:39:37.930
Và nếu chúng ta có thể, nếu chúng ta có một máy in ma trận chấm gắn vào chúng ta,

625
00:39:37.930 --> 00:39:41.929
thì các pixel sẽ xuất hiện, nhưng những gì ở giữa không phải là pixel.

626
00:39:43.210 --> 00:39:46.620
Và vì vậy tôi nghĩ suy nghĩ chỉ là những vectơ lớn này, và

627
00:39:46.620 --> 00:39:48.460
các vectơ lớn có sức mạnh nhân quả.

628
00:39:48.460 --> 00:39:50.490
Chúng gây ra các vectơ lớn khác, và

629
00:39:50.490 --> 00:39:56.100
điều đó hoàn toàn không giống như quan điểm AI tiêu chuẩn rằng suy nghĩ là biểu hiện tượng trưng.

630
00:39:56.100 --> 00:39:56.700
Tôi thấy, tốt,

631
00:39:57.740 --> 00:40:01.560
tôi đoán AI chắc chắn đang đi đến quan điểm mới này trong những ngày này.

632
00:40:01.560 --> 00:40:02.660
Một số trong số đó,

633
00:40:02.660 --> 00:40:08.230
tôi nghĩ rằng rất nhiều người trong AI vẫn nghĩ rằng suy nghĩ phải là biểu hiện tượng trưng.

634
00:40:08.230 --> 00:40:09.780
Cảm ơn bạn rất nhiều vì đã thực hiện cuộc phỏng vấn này.

635
00:40:09.780 --> 00:40:12.970
Thật thú vị khi nghe Deep Learning đã phát triển như thế nào trong những năm

636
00:40:12.970 --> 00:40:17.680
qua, cũng như cách bạn vẫn đang giúp thúc đẩy nó vào tương lai, vì vậy cảm ơn bạn, Jeff.